# @package _global_

defaults:
  - override /data: til_permuted_mnist.yaml
  - override /model: finetuning_mlp_til.yaml
  - override /callbacks: default.yaml
  - override /logger: many_loggers.yaml
  - override /trainer: default.yaml

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

experiment_name: "Finetuning_1"

tags: ["TIL", "Permuted MNIST", "MLP", "Finetuning"]

seed: 12345


# major settings overwrite here
# refer to the detailed configs for other settings

data:
  batch_size: 128
  num_tasks: 50

model:

  backbone:
    input_dim: 784
    hidden_dims: [256, 100]
    output_dim: 64
    # input_channels: 1

  optimizer: 
    lr: 0.001