# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - override /data: til_permuted_omniglot.yaml
  - override /model: finetuning/mlp_til.yaml
  - override /callbacks: default.yaml
  - override /trainer: default.yaml

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

experiment_name: "finetuning_pomniglot"

tags: ["TIL", "Permuted Omniglot", "MLP", "Finetuning"]

seed: 12345

model:
  backbone:
    input_dim: 11025
    
trainer:
  max_epochs: 10



